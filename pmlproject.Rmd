---
title: "Practical Machine Learning Project: Predicting Exercise Classes"
author: "Logan Yang"
date: "August 23, 2014"
output: html_document
---
        
        
```{r setoptions, echo=FALSE}
library(knitr)
opts_chunk$set(echo = TRUE, cache = TRUE)
```

## Introduction

Using devices such as *Jawbone Up*, *Nike FuelBand*, and *Fitbit* it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior. People rarely quantify how well they do the exercise. In this data set, six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E). Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes.

Read more: http://groupware.les.inf.puc-rio.br/har#ixzz3BCoshVQN

In this project, the machine learning model will predict the manner in which the participants did the exercise. It is a multi-class classification problem. The outcome is the "classe" variable. 

### Data Processing and Feature Selection

Load the data from the csv files, 

```{r load & process,results='hide',warning=FALSE}
library(caret)
library(randomForest)
data <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
```

Select relevant variables for classification. In this case, all the columns with more than 100 NAs and variances less or equal to 10 are eliminated.

```{r,results='hide',warning=FALSE}
## eliminate major NA columns
dt <- data[,colSums(is.na(data)) < 100]
## find variabls with larger variance
colvar <- apply(dt, 2, var)
selectBigVar <- which(colvar > 10)
selectBigVar <- as.vector(selectBigVar)
```

From the [paper](http://groupware.les.inf.puc-rio.br/work.jsf?p1=11201), we know that there are some features which are more relevant than others according to the result of the Mark Hall's selection algorithm based on correlation. And intuitively, the actual sensor recordings of the exercise should be significant for classification, hence here we eliminate the statistical variables. Most of those variables are missing or have low variance, which supports the reasoning in the selection method above.

```{r,results='hide',warning=FALSE}
## find useful variables manually according to knowledge
selectManual <- c(2, 8, 9, 24:26, 30:33, 37:39, 49, 50, 65:67, 71, 72, 83, 87:89, 93)
combine <- unique(as.vector(rbind(selectBigVar, selectManual)))
# select <- selectManual
select <- combine[-1]
dt <- dt[select]
```

Plot the frequencies of the 5 classes to get a feeling how many there are in each class.

```{r}
## plot the class frequencies
barplot(table(dt$classe), main = "Frequencies of the 5 classes")
```

### Data Slicing, Prediction and Cross Validation

The data set is not a small one, it has 19622 observations and 45 variables after feature selection. We can partition it into a training set and a cross validation set with size 60:40 in the conventional way.

```{r}
set.seed(123)
inTrain <- createDataPartition(dt$classe, p = 3/5, list = FALSE)
training <- dt[inTrain,]
cv <- dt[-inTrain,]
```

Now do the model training and prediction,

```{r, echo=TRUE}
## use randomforest to train the multi-class classifier
fit <- randomForest(classe ~., data = training)
predcv <- predict(fit, cv)
fit
confusionMatrix(predcv, cv$classe)
```

From the tables we see that the random forest performs reasonably well on both the training set and the cross validation set. The in-sample error rate is 0.02% (training accuracy = 99.8%), and the model yields a very low out-of-sample error rate, which is only 0.15%. 

### Model Selection

Since the sample size is large enough, instead of doing K-fold cross validation, I used the conventional method of the 60:40 split and the out-of-sample error is already quite small. For this multi-class classification problem, the random forest performs well and runs efficiently. Comparisons were done by using one.vs.all method with logistic regression and naive bayes classifier, and random forest proved to be the top choice among most cases.

### Prediction Result for the Testing Set

These are the final prediction results, which scored full mark in the submission.

```{r, echo=TRUE}
as.character(predict(fit, testing))
```


### References
* Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013

* Practical Machine Learning, Data Science Specialization offered by Coursera and Johns Hopkins University, Aug 2014




